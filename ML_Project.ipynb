{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "ffQV-WGqaAff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from RNN import RNN\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FyJNyGQtlTV5",
        "outputId": "23a02ab9-4a44-4f0e-adbc-b30c7dc45866"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      Time       Date   High    Low     Volume   Open  Close  TargetNextClose\n",
            "1663     0   3-Jan-11  47.18  46.41  111280407  46.52  47.08            47.33\n",
            "1662     1   4-Jan-11  47.50  46.88   77337001  47.49  47.33            47.71\n",
            "1661     2   5-Jan-11  47.76  47.07   63879193  47.08  47.71            47.68\n",
            "1660     3   6-Jan-11  47.89  47.56   75106626  47.82  47.68            48.02\n",
            "1659     4   7-Jan-11  48.05  47.41   77982212  47.71  48.02            48.92\n",
            "1658     5  10-Jan-11  49.03  48.17  112139482  48.40  48.92            48.81\n",
            "1657     6  11-Jan-11  49.28  48.50  111019993  49.27  48.81            49.20\n",
            "1656     7  12-Jan-11  49.20  48.86   75644310  49.04  49.20            49.38\n",
            "1655     8  13-Jan-11  49.52  49.12   74536182  49.31  49.38            49.78\n",
            "1654     9  14-Jan-11  49.78  49.21   77209748  49.41  49.78            48.66\n",
            "(1663, 8)\n",
            "    High    Low     Volume   Open  Close\n",
            "0  47.18  46.41  111280407  46.52  47.08\n",
            "1  47.50  46.88   77337001  47.49  47.33\n",
            "2  47.76  47.07   63879193  47.08  47.71\n",
            "3  47.89  47.56   75106626  47.82  47.68\n",
            "4  48.05  47.41   77982212  47.71  48.02\n",
            "5  49.03  48.17  112139482  48.40  48.92\n",
            "6  49.28  48.50  111019993  49.27  48.81\n",
            "7  49.20  48.86   75644310  49.04  49.20\n",
            "8  49.52  49.12   74536182  49.31  49.38\n",
            "9  49.78  49.21   77209748  49.41  49.78\n",
            "        High     Low     Volume    Open   Close\n",
            "0      47.18   46.41  111280407   46.52   47.08\n",
            "1      47.50   46.88   77337001   47.49   47.33\n",
            "2      47.76   47.07   63879193   47.08   47.71\n",
            "3      47.89   47.56   75106626   47.82   47.68\n",
            "4      48.05   47.41   77982212   47.71   48.02\n",
            "...      ...     ...        ...     ...     ...\n",
            "1658  157.40  155.69   20559852  156.07  156.39\n",
            "1659  158.92  156.67   21870321  157.06  158.81\n",
            "1660  161.83  158.27   36205896  158.60  160.08\n",
            "1661  161.27  159.11   26131530  159.26  161.06\n",
            "1662  160.00  154.63   40804273  159.90  155.32\n",
            "\n",
            "[1663 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "url = \"https://github.com/swarj/MLProject/raw/main/apple_share_price.csv\" #get the dataset\n",
        "raw_df = pd.read_csv(url)\n",
        "raw_df = raw_df.loc[::-1] #reverse order of rows to chronologically make it go from past --> present\n",
        "raw_df = raw_df.assign(Time=range(len(raw_df)))\n",
        "df = raw_df.reindex(['Time','Date', 'High', 'Low', 'Volume', 'Open', 'Close'], axis = 1) #make target variable last column, if we want close instead of open we can switch it\n",
        "#we can try to predict the close value for the following day, need to add target close value  \n",
        "df['TargetNextClose'] = df['Close'].shift(-1)\n",
        "df.drop(df.tail(1).index,inplace=True) # drop last rows\n",
        "df.style\n",
        "print(df.head(10))\n",
        "print(df.shape)\n",
        "df.reset_index(inplace=True)\n",
        "data_set = df.iloc[:, 0:8]\n",
        "pd.set_option('display.max_columns', None)\n",
        "data_set = data_set.drop(columns=[\"Date\", \"Time\", \"index\"], axis=1)\n",
        "print(data_set.head(10))\n",
        "\n",
        "#(Jason) i added this for my forward method\n",
        "# Parse the date column as a datetime object\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "# Convert the date column to a float timestamp\n",
        "df['Date'] = df['Date'].apply(lambda x: x.timestamp())\n",
        "# Reset the index\n",
        "df.reset_index(inplace=True)\n",
        "\n",
        "# Select the first 8 columns as the dataset\n",
        "# Print the first 10 rows of the updated dataframe\n",
        "print(data_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1633, 1)\n",
            "[ 51.31  51.54  51.04 ... 158.6  159.26 159.9 ]\n"
          ]
        }
      ],
      "source": [
        "X = []\n",
        "backcandles = 30\n",
        "for j in range(8):\n",
        "    X.append([])\n",
        "    for i in range(backcandles, data_set_scaled.shape[0]):\n",
        "        X[j].append(data_set_scaled[i-backcandles:i, j])\n",
        "\n",
        "X=np.moveaxis(X, [0], [2])\n",
        "\n",
        "X, yi =np.array(X), np.array(data_set_scaled[backcandles:,-1])\n",
        "y=np.reshape(yi,(len(yi),1))\n",
        "print(y.shape)\n",
        "print(yi)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.39327279130581816, -0.49558649716893216, -0.5735049935055325, -0.7557691741758915]\n",
            "[ 0.39327279 -0.4955865  -0.57350499 -0.75576917]\n"
          ]
        }
      ],
      "source": [
        "# Create an instance \n",
        "rnn = RNN(input_size=2, output_size=1, hidden_size=3)\n",
        "# Define some inputs\n",
        "input_data = [[1, 0], [0, 1], [0.2550690257394217, 0.49543508709194095], [0, 0]]\n",
        "output_data = [[2],[2],[2],[2]]\n",
        "# Call the forward method and print the outputs\n",
        "outputs = rnn.forward_pass(input_data)\n",
        "print(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = []\n",
        "backcandles = 30\n",
        "#print(type(data_set))\n",
        "#print(data_set.shape[0])\n",
        "#print(data_set[40-backcandles:40, 5])\n",
        "for j in range(8):\n",
        "    X.append([])\n",
        "    for i in range(backcandles, data_set_scaled.shape[0]):\n",
        "        X[j].append(data_set_scaled[i-backcandles:i, j])\n",
        "\n",
        "X=np.moveaxis(X, [0], [2])\n",
        "\n",
        "X, yi =np.array(X), np.array(data_set_scaled[backcandles:,-1])\n",
        "y=np.reshape(yi,(len(yi),1))\n",
        "print(y.shape)\n",
        "print(yi)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: [[206.91933897]]\n",
            "Loss: [[5255.35039252]]\n",
            "Loss: [[5326.531209]]\n",
            "Loss: [[5868.5462863]]\n",
            "Loss: [[5868.58063614]]\n",
            "Loss: [[6430.03500839]]\n",
            "Loss: [[6436.88227211]]\n",
            "Loss: [[6436.26820178]]\n",
            "Loss: [[6431.95011078]]\n",
            "Loss: [[6434.52194476]]\n",
            "Mean Squared Error: 3.4615748540559066\n"
          ]
        }
      ],
      "source": [
        "\n",
        "hidden_units = 64\n",
        "time_steps = 30\n",
        "input_features = 4\n",
        "learning_rate = 0.01\n",
        "\n",
        "Wxh = np.random.randn(hidden_units, input_features) * 0.01\n",
        "Whh = np.random.randn(hidden_units, hidden_units) * 0.01\n",
        "Why = np.random.randn(1, hidden_units) * 0.01\n",
        "bh = np.zeros((hidden_units, 1))\n",
        "by = np.zeros((1, 1))\n",
        "\n",
        "def forward_propagation(X, Y, h_prev):\n",
        "    cache = {}\n",
        "    cache['h'] = {}\n",
        "    cache['x'] = {}\n",
        "    cache['h'][-1] = np.copy(h_prev)\n",
        "    loss = 0\n",
        "    \n",
        "    for t in range(len(X)):\n",
        "        cache['x'][t] = X[t].reshape(-1, 1)\n",
        "        cache['h'][t] = np.tanh(np.dot(Wxh, cache['x'][t]) + np.dot(Whh, cache['h'][t-1]) + bh)\n",
        "        Y_pred = np.dot(Why, cache['h'][t]) + by\n",
        "        loss += (Y[t] - Y_pred)**2\n",
        "        \n",
        "    cache['loss'] = loss\n",
        "    cache['Y_pred'] = Y_pred\n",
        "    \n",
        "    return cache\n",
        "\n",
        "def backward_propagation(X, Y, cache):\n",
        "    dWxh = np.zeros_like(Wxh)\n",
        "    dWhh = np.zeros_like(Whh)\n",
        "    dWhy = np.zeros_like(Why)\n",
        "    dbh = np.zeros_like(bh)\n",
        "    dby = np.zeros_like(by)\n",
        "    dh_next = np.zeros_like(cache['h'][0])\n",
        "    \n",
        "    for t in reversed(range(len(X))):\n",
        "        dy = -2 * (Y[t] - cache['Y_pred'])\n",
        "        dWhy += np.dot(dy, cache['h'][t].T)\n",
        "        dby += dy\n",
        "        \n",
        "        dh = np.dot(Why.T, dy) + dh_next\n",
        "        dh_raw = (1 - cache['h'][t]**2) * dh\n",
        "        dbh += dh_raw\n",
        "        dWxh += np.dot(dh_raw, cache['x'][t].T)\n",
        "        dWhh += np.dot(dh_raw, cache['h'][t-1].T)\n",
        "        dh_next = np.dot(Whh.T, dh_raw)\n",
        "        \n",
        "    for dparam in [dWxh, dWhh, dWhy, dbh, dby]:\n",
        "        np.clip(dparam, -5, 5, out=dparam)\n",
        "        \n",
        "    return dWxh, dWhh, dWhy, dbh, dby\n",
        "\n",
        "h_prev = np.zeros((hidden_units, 1))\n",
        "\n",
        "data = data_set\n",
        "data = sc.fit_transform(data)\n",
        "data = pd.DataFrame(data)\n",
        "X, X_test = np.array(data.iloc[:, :-1])[:splitlimit], np.array(data.iloc[:, :-1])[splitlimit:]\n",
        "Y, Y_test = np.array(data.iloc[:, -1]).reshape(-1, 1)[:splitlimit], np.array(data.iloc[:, -1]).reshape(-1, 1)[splitlimit:]\n",
        "\n",
        "for i in range(100):\n",
        "    cache = forward_propagation(X, Y, h_prev)\n",
        "    dWxh, dWhh, dWhy, dbh, dby = backward_propagation(X, Y, cache)\n",
        "    Wxh -= learning_rate * dWxh\n",
        "    Whh -= learning_rate * dWhh\n",
        "    Why -= learning_rate * dWhy\n",
        "    bh -= learning_rate * dbh\n",
        "    by -= learning_rate * dby\n",
        "    h_prev = cache['h'][len(X) - 1]\n",
        "    if i % 10 == 0:\n",
        "        print('Loss:', cache['loss'])\n",
        "\n",
        "h_prev = np.zeros((hidden_units, 1))\n",
        "Y_preds = []\n",
        "for t in range(len(X_test)):\n",
        "    cache = forward_propagation([X_test[t]], [Y_test[t]], h_prev)\n",
        "    Y_preds.append(cache['Y_pred'])\n",
        "    h_prev = cache['h'][0]\n",
        "\n",
        "# calculate the MSE\n",
        "MSE = np.mean((Y_test - Y_preds)**2)\n",
        "print('Mean Squared Error:', MSE)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
